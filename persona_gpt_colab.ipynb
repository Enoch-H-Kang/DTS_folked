{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona to GPT-4 Interface - Google Colab Version\n",
    "\n",
    "This notebook allows you to input a persona and get responses from GPT-4. This is a standalone version that works in Google Colab without local file dependencies.\n",
    "\n",
    "## Setup\n",
    "1. Run the first cell to install dependencies\n",
    "2. Set your OpenAI API key when prompted\n",
    "3. Modify the persona and questions in the designated cells\n",
    "4. Run cells to get GPT-4 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install openai python-dotenv tenacity tqdm\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Dict, Optional, Union, Callable, List, Tuple\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import httpx\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import getpass\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    os.environ['OPENAI_API_KEY'] = api_key\n",
    "    print(\"‚úÖ API key set successfully\")\n",
    "else:\n",
    "    print(\"‚úÖ API key already set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings (from openai_config.yaml)\n",
    "CONFIG = {\n",
    "    'model_name': 'gpt-4.1-mini-2025-04-14',\n",
    "    'temperature': 0.0,\n",
    "    'max_tokens': 16384,\n",
    "    'max_retries': 10,\n",
    "    'system_instruction': \"\"\"You are an AI assistant. Your task is to answer the 'New Survey Question' as if you are the person described in the 'Persona Profile' (which consists of their past survey responses). \n",
    "Adhere to the persona by being consistent with their previous answers and stated characteristics. \n",
    "Follow all instructions provided for the new question carefully regarding the format of your answer.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "print(f\"Temperature: {CONFIG['temperature']}\")\n",
    "print(f\"Max tokens: {CONFIG['max_tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Helper Functions (simplified version)\n",
    "class LLMConfig:\n",
    "    def __init__(self, model_name: str, temperature: float = 0.7, max_tokens: Optional[int] = None, \n",
    "                 system_instruction: Optional[str] = None, max_retries: int = 10):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.system_instruction = system_instruction\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    retry=retry_if_exception_type((ConnectionError, TimeoutError, openai.APITimeoutError, \n",
    "                                   openai.APIConnectionError, openai.RateLimitError, openai.APIError)),\n",
    "    reraise=True\n",
    ")\n",
    "async def get_openai_response(prompt: str, config: LLMConfig) -> Dict[str, Union[str, Dict]]:\n",
    "    \"\"\"Get response from OpenAI API with retry logic.\"\"\"\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "    \n",
    "    async with httpx.AsyncClient(timeout=1000.0) as client:\n",
    "        aclient = openai.AsyncOpenAI(api_key=api_key, http_client=client)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": config.system_instruction}, \n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = await aclient.chat.completions.create(\n",
    "                model=config.model_name, \n",
    "                messages=messages, \n",
    "                temperature=config.temperature, \n",
    "                max_tokens=config.max_tokens\n",
    "            )\n",
    "            \n",
    "            usage_details = {\n",
    "                \"prompt_token_count\": response.usage.prompt_tokens,\n",
    "                \"completion_token_count\": response.usage.completion_tokens,\n",
    "                \"total_token_count\": response.usage.total_tokens\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"response_text\": response.choices[0].message.content, \n",
    "                \"usage_details\": usage_details\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"API call failed: {str(e)}\"}\n",
    "\n",
    "def create_persona_prompt(persona_profile: str, new_question: str) -> str:\n",
    "    \"\"\"Create a formatted prompt with persona profile and new question.\"\"\"\n",
    "    return f\"\"\"Persona Profile:\n",
    "{persona_profile}\n",
    "\n",
    "New Survey Question:\n",
    "{new_question}\"\"\"\n",
    "\n",
    "async def get_gpt_response(persona_profile: str, new_question: str, config: LLMConfig) -> Dict:\n",
    "    \"\"\"Get GPT response for a given persona and question.\"\"\"\n",
    "    prompt = create_persona_prompt(persona_profile, new_question)\n",
    "    return await get_openai_response(prompt, config)\n",
    "\n",
    "# Create LLM configuration\n",
    "llm_config = LLMConfig(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    temperature=CONFIG['temperature'],\n",
    "    max_tokens=CONFIG['max_tokens'],\n",
    "    system_instruction=CONFIG['system_instruction'],\n",
    "    max_retries=CONFIG['max_retries']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM helper functions and configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Your Persona Profile\n",
    "\n",
    "Modify the cell below to customize your persona's characteristics and previous survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your persona profile\n",
    "persona_profile = \"\"\"\n",
    "Age: 35\n",
    "Gender: Female\n",
    "Education: Bachelor's degree in Business Administration\n",
    "Income: $75,000 annually\n",
    "Location: Urban area, East Coast\n",
    "Previous survey responses:\n",
    "- When asked about work-life balance: \"I prioritize family time and try to maintain clear boundaries between work and personal life.\"\n",
    "- When asked about technology adoption: \"I'm generally cautious about new technologies and prefer to wait until they're proven and widely adopted.\"\n",
    "- When asked about spending habits: \"I'm a careful budgeter who prefers to save money for future goals rather than spend on immediate gratification.\"\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Persona profile set:\")\n",
    "print(persona_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Your Survey Question\n",
    "\n",
    "Enter the new survey question you want the persona to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your new survey question\n",
    "new_question = \"\"\"\n",
    "How do you feel about remote work opportunities? Please provide your opinion in 2-3 sentences, considering your work-life balance preferences and technology comfort level.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"New survey question:\")\n",
    "print(new_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GPT-4 Response\n",
    "\n",
    "Run the cell below to get the GPT-4 response as your defined persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GPT-4 response\n",
    "response_data = await get_gpt_response(persona_profile, new_question, llm_config)\n",
    "\n",
    "# Display the results\n",
    "if \"error\" in response_data and response_data[\"error\"]:\n",
    "    print(\"‚ùå Error occurred:\")\n",
    "    print(response_data[\"error\"])\n",
    "else:\n",
    "    print(\"ü§ñ GPT-4 Response as the persona:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(response_data[\"response_text\"])\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display usage statistics\n",
    "    if \"usage_details\" in response_data:\n",
    "        usage = response_data[\"usage_details\"]\n",
    "        print(f\"\\nüìä Token usage:\")\n",
    "        print(f\"- Prompt tokens: {usage.get('prompt_token_count', 'N/A')}\")\n",
    "        print(f\"- Completion tokens: {usage.get('completion_token_count', 'N/A')}\")\n",
    "        print(f\"- Total tokens: {usage.get('total_token_count', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "\n",
    "Use the cell below to test different questions with the same persona. Simply modify the question and re-run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing - modify this question and re-run\n",
    "interactive_question = \"What is your opinion on investing in cryptocurrency?\"\n",
    "\n",
    "print(f\"üîÑ Testing question: {interactive_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "response_data = await get_gpt_response(persona_profile, interactive_question, llm_config)\n",
    "\n",
    "if \"error\" in response_data and response_data[\"error\"]:\n",
    "    print(\"‚ùå Error occurred:\")\n",
    "    print(response_data[\"error\"])\n",
    "else:\n",
    "    print(\"ü§ñ Persona Response:\")\n",
    "    print(response_data[\"response_text\"])\n",
    "    print(\"-\" * 50)\n",
    "    if \"usage_details\" in response_data:\n",
    "        print(f\"üìä Tokens used: {response_data['usage_details'].get('total_token_count', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Testing\n",
    "\n",
    "Test multiple questions at once with the same persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple questions to test\n",
    "test_questions = [\n",
    "    \"How do you prefer to shop for groceries?\",\n",
    "    \"What factors influence your choice of vacation destinations?\",\n",
    "    \"How do you stay informed about current events?\",\n",
    "    \"What is your opinion on electric vehicles?\",\n",
    "    \"How do you approach making major financial decisions?\"\n",
    "]\n",
    "\n",
    "print(\"üîÑ Processing multiple questions...\\n\")\n",
    "\n",
    "total_tokens = 0\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"‚ùì Question {i}: {question}\")\n",
    "    \n",
    "    response_data = await get_gpt_response(persona_profile, question, llm_config)\n",
    "    \n",
    "    if \"error\" in response_data and response_data[\"error\"]:\n",
    "        print(f\"‚ùå Error: {response_data['error']}\")\n",
    "    else:\n",
    "        print(f\"ü§ñ Response: {response_data['response_text']}\")\n",
    "        if \"usage_details\" in response_data:\n",
    "            tokens = response_data['usage_details'].get('total_token_count', 0)\n",
    "            total_tokens += tokens\n",
    "            print(f\"üìä Tokens: {tokens}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "print(f\"üéØ Total tokens used for all questions: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Persona Creator\n",
    "\n",
    "Use this section to quickly create and test a new persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom persona\n",
    "custom_persona = \"\"\"\n",
    "Age: 28\n",
    "Gender: Male\n",
    "Education: Master's degree in Computer Science\n",
    "Income: $95,000 annually\n",
    "Location: San Francisco, California\n",
    "Previous survey responses:\n",
    "- When asked about work preferences: \"I thrive in fast-paced, innovative environments and enjoy tackling complex technical challenges.\"\n",
    "- When asked about technology: \"I'm an early adopter who loves trying new gadgets and software as soon as they're released.\"\n",
    "- When asked about lifestyle: \"I value experiences over material possessions and prefer to spend money on travel and learning opportunities.\"\n",
    "\"\"\".strip()\n",
    "\n",
    "# Test question for the custom persona\n",
    "custom_question = \"How do you feel about AI tools in the workplace?\"\n",
    "\n",
    "print(\"üé≠ Testing custom persona:\")\n",
    "print(custom_persona)\n",
    "print(f\"\\n‚ùì Question: {custom_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "response_data = await get_gpt_response(custom_persona, custom_question, llm_config)\n",
    "\n",
    "if \"error\" in response_data and response_data[\"error\"]:\n",
    "    print(f\"‚ùå Error: {response_data['error']}\")\n",
    "else:\n",
    "    print(f\"ü§ñ Response: {response_data['response_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}