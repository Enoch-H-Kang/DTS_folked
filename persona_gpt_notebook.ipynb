{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Persona to GPT-4 Interface\n\nThis notebook allows you to input a persona and get responses from GPT-4 using the configuration from the OpenAI config file.\n\n## Setup Requirements\n\n1. **Install dependencies**: Make sure you have Poetry installed and run:\n   ```bash\n   poetry install\n   ```\n\n2. **Environment variables**: Set your OpenAI API key:\n   ```bash\n   export OPENAI_API_KEY=\"your-api-key-here\"\n   ```\n   Or create a `.env` file in the project root with:\n   ```\n   OPENAI_API_KEY=your-api-key-here\n   ```\n\n3. **Run in Poetry environment**: Start Jupyter in the Poetry environment:\n   ```bash\n   poetry run jupyter notebook\n   ```\n\n## Dependencies Used\n\nThis notebook uses the following key dependencies from `pyproject.toml`:\n- `openai` (^1.78.1) - OpenAI API client\n- `python-dotenv` (^1.1.0) - Environment variable management\n- `tenacity` (^9.1.2) - Retry logic for API calls\n- `tqdm` (^4.66.0) - Progress bars\n- `google-generativeai` (^0.8.5) - Also supports Gemini if needed",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Check if we're running in the correct Poetry environment\nimport sys\nimport subprocess\n\ntry:\n    # Check if we're in a Poetry environment\n    result = subprocess.run(['poetry', 'env', 'info', '--path'], \n                          capture_output=True, text=True, check=True)\n    poetry_env_path = result.stdout.strip()\n    if poetry_env_path in sys.executable:\n        print(\"✅ Running in Poetry environment\")\n    else:\n        print(\"⚠️  Not running in Poetry environment. Please start with: poetry run jupyter notebook\")\nexcept:\n    print(\"⚠️  Poetry not found or not in Poetry environment\")\n\n# Import required libraries\nimport os\nimport asyncio\nimport yaml\nimport sys\nfrom pathlib import Path\n\n# Add the text_simulation directory to the path to import the LLM helper\nsys.path.append('text_simulation')\nfrom llm_helper import LLMConfig, process_prompts_batch\n\n# Load environment variables if .env file exists\ntry:\n    from dotenv import load_dotenv\n    load_dotenv()\n    print(\"✅ dotenv loaded successfully\")\nexcept ImportError:\n    print(\"⚠️  dotenv not installed. Make sure OPENAI_API_KEY is set in your environment.\")\n\n# Check if OpenAI API key is available\nif os.getenv('OPENAI_API_KEY'):\n    print(\"✅ OPENAI_API_KEY found in environment\")\nelse:\n    print(\"❌ OPENAI_API_KEY not found. Please set it in your environment or .env file\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from OpenAI config file\n",
    "config_path = \"text_simulation/configs/openai_config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as file:\n",
    "    config_data = yaml.safe_load(file)\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(f\"Model: {config_data['model_name']}\")\n",
    "print(f\"Temperature: {config_data['temperature']}\")\n",
    "print(f\"Max tokens: {config_data['max_tokens']}\")\n",
    "print(f\"System instruction: {config_data['system_instruction'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM configuration\n",
    "llm_config = LLMConfig(\n",
    "    model_name=config_data['model_name'],\n",
    "    temperature=config_data['temperature'],\n",
    "    max_tokens=config_data['max_tokens'],\n",
    "    system_instruction=config_data['system_instruction'],\n",
    "    max_retries=config_data['max_retries'],\n",
    "    max_concurrent_requests=1  # Set to 1 for notebook usage\n",
    ")\n",
    "\n",
    "print(\"LLM configuration created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_persona_prompt(persona_profile, new_question):\n",
    "    \"\"\"Create a formatted prompt with persona profile and new question.\"\"\"\n",
    "    prompt = f\"\"\"Persona Profile:\n",
    "{persona_profile}\n",
    "\n",
    "New Survey Question:\n",
    "{new_question}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "async def get_gpt_response(persona_profile, new_question):\n",
    "    \"\"\"Get GPT-4 response for a given persona and question.\"\"\"\n",
    "    prompt = create_persona_prompt(persona_profile, new_question)\n",
    "    \n",
    "    # Create a single prompt tuple\n",
    "    prompts = [(\"persona_response\", prompt)]\n",
    "    \n",
    "    # Process the prompt\n",
    "    results = await process_prompts_batch(\n",
    "        prompts, \n",
    "        llm_config, \n",
    "        provider=\"openai\",\n",
    "        desc=\"Getting GPT-4 response\"\n",
    "    )\n",
    "    \n",
    "    return results[\"persona_response\"]\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Your Persona and Question\n",
    "\n",
    "Modify the cells below to input your persona profile and the new survey question you want the persona to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your persona profile\n",
    "persona_profile = \"\"\"\n",
    "Age: 35\n",
    "Gender: Female\n",
    "Education: Bachelor's degree in Business Administration\n",
    "Income: $75,000 annually\n",
    "Location: Urban area, East Coast\n",
    "Previous survey responses:\n",
    "- When asked about work-life balance: \"I prioritize family time and try to maintain clear boundaries between work and personal life.\"\n",
    "- When asked about technology adoption: \"I'm generally cautious about new technologies and prefer to wait until they're proven and widely adopted.\"\n",
    "- When asked about spending habits: \"I'm a careful budgeter who prefers to save money for future goals rather than spend on immediate gratification.\"\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Persona profile set:\")\n",
    "print(persona_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your new survey question\n",
    "new_question = \"\"\"\n",
    "How do you feel about remote work opportunities? Please provide your opinion in 2-3 sentences, considering your work-life balance preferences and technology comfort level.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"New survey question:\")\n",
    "print(new_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GPT-4 Response\n",
    "\n",
    "Run the cell below to get the GPT-4 response as the defined persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GPT-4 response\n",
    "response_data = await get_gpt_response(persona_profile, new_question)\n",
    "\n",
    "# Display the results\n",
    "if \"error\" in response_data and response_data[\"error\"]:\n",
    "    print(\"Error occurred:\")\n",
    "    print(response_data[\"error\"])\n",
    "else:\n",
    "    print(\"GPT-4 Response as the persona:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(response_data[\"response_text\"])\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display usage statistics\n",
    "    if \"usage_details\" in response_data:\n",
    "        usage = response_data[\"usage_details\"]\n",
    "        print(f\"\\nToken usage:\")\n",
    "        print(f\"- Prompt tokens: {usage.get('prompt_token_count', 'N/A')}\")\n",
    "        print(f\"- Completion tokens: {usage.get('completion_token_count', 'N/A')}\")\n",
    "        print(f\"- Total tokens: {usage.get('total_token_count', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Mode\n",
    "\n",
    "Use the cell below to interactively test different questions with the same persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing - modify this question and re-run\n",
    "interactive_question = \"What is your opinion on investing in cryptocurrency?\"\n",
    "\n",
    "response_data = await get_gpt_response(persona_profile, interactive_question)\n",
    "\n",
    "if \"error\" in response_data and response_data[\"error\"]:\n",
    "    print(\"Error occurred:\")\n",
    "    print(response_data[\"error\"])\n",
    "else:\n",
    "    print(f\"Question: {interactive_question}\")\n",
    "    print(\"\\nPersona Response:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(response_data[\"response_text\"])\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Testing\n",
    "\n",
    "Test multiple questions at once with the same persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple questions to test\n",
    "test_questions = [\n",
    "    \"How do you prefer to shop for groceries?\",\n",
    "    \"What factors influence your choice of vacation destinations?\",\n",
    "    \"How do you stay informed about current events?\"\n",
    "]\n",
    "\n",
    "# Process all questions\n",
    "print(\"Processing multiple questions...\\n\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    \n",
    "    response_data = await get_gpt_response(persona_profile, question)\n",
    "    \n",
    "    if \"error\" in response_data and response_data[\"error\"]:\n",
    "        print(f\"Error: {response_data['error']}\")\n",
    "    else:\n",
    "        print(f\"Response: {response_data['response_text']}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}